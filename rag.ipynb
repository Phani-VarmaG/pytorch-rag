{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phani\\AppData\\Local\\Temp\\ipykernel_5184\\3352308848.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"phi3\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"phi3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phani\\AppData\\Local\\Temp\\ipykernel_5184\\4070198614.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Generate embeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "# Load saved Vector Store\n",
    "vectorstore = FAISS.load_local(\"faiss_index\", embedding_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is torch nn', 'result': \"torch.nn (or just 'nn') refers to a module subclassing library that provides classes, functions and methods designed specifically for neural networks in Python using the Pytorch framework. It offers pre-defined layers like Convolutional Layer (`Conv2d`), Pooling Layer (`MaxPool2d`, `AvgPool2d`), Recurrent Neural Network layer such as RNNs(`RNN`,`LSTM`) and more, along with other useful utilities. It is a part of the PyTorch library for deep learning research group in Facebook's artificial intelligence division, which provides GPU-accelerated operations also via CUDA support (for NVIDIA GPUs).\\nYou can find it here: https://pytorch.org/docs/stable/_modules/torch/nn/. \\nRemember to import the 'torch' library in your Python script before using these layers or methods provided by torch.nn, as shown below:\\n```python\\nimport torch\\nfrom torch import nn\\n# Define and use a layer from NN here... like Linear Layer for example\\nlinear_layer = nn.Linear(20, 40)\\ninput = torch.randn((5,20)) # input tensor with shape (batch size=5 ,features=20 )\\noutput = linear_layer(input)\\n```\", 'source_documents': [Document(id='22e8279b-64de-4360-a409-601b039aa24e', metadata={}, page_content='torch.var(input, unbiased=False)\\n.\\nThis layer uses statistics computed from input data in both training and\\nevaluation modes.\\nParameters\\nnum_groups\\n(\\nint\\n) – number of groups to separate the channels into\\nnum_channels\\n(\\nint\\n) – number of channels expected in input\\neps\\n(\\nfloat\\n) – a value added to the denominator for numerical stability. Default: 1e-5\\naffine\\n(\\nbool\\n) – a boolean value that when set to\\nTrue\\n, this module'), Document(id='b86065fb-1fd2-4fa8-b139-bbee9f06c192', metadata={}, page_content='TransformerEncoderLayer\\n¶\\nclass\\ntorch.nn.\\nTransformerEncoderLayer\\n(\\nd_model\\n,\\nnhead\\n,\\ndim_feedforward=2048\\n,\\ndropout=0.1\\n,\\nactivation=<function\\nrelu>\\n,\\nlayer_norm_eps=1e-05\\n,\\nbatch_first=False\\n,\\nnorm_first=False\\n,\\nbias=True\\n,\\ndevice=None\\n,\\ndtype=None\\n)\\n[source]\\n[source]\\n¶\\nTransformerEncoderLayer is made up of self-attn and feedforward network.\\nNote\\nSee\\nthis tutorial\\nfor an in depth discussion of the performant building blocks PyTorch offers for building your own\\ntransformer layers.'), Document(id='3275c93e-6ed2-4328-8ccd-886312dfca95', metadata={}, page_content='TransformerDecoderLayer\\n¶\\nclass\\ntorch.nn.\\nTransformerDecoderLayer\\n(\\nd_model\\n,\\nnhead\\n,\\ndim_feedforward=2048\\n,\\ndropout=0.1\\n,\\nactivation=<function\\nrelu>\\n,\\nlayer_norm_eps=1e-05\\n,\\nbatch_first=False\\n,\\nnorm_first=False\\n,\\nbias=True\\n,\\ndevice=None\\n,\\ndtype=None\\n)\\n[source]\\n[source]\\n¶\\nTransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network.\\nNote\\nSee\\nthis tutorial\\nfor an in depth discussion of the performant building blocks PyTorch offers for building your own')]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "result = rag_chain.invoke(\"What is torch nn\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
